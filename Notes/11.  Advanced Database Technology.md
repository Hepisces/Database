# 1. Advanced Database Technology

## 1.1. DuckDB

```bash
brew install duckdb
```

> DuckDB is a fast **analytical, in-process** database system

- Motivation: Existing databases are too cumbersome and costly for data scientists, data analysts, etc. to learn.

- What DuckDB do？ In windows, just a 10MB zip file, and can do almost everything pg,... can do.

- What it focus on? `SELECT`

[see in Wiki](https://en.wikipedia.org/wiki/DuckDB)

### 1.1.1. When to use

For analytical loads:

- Faster than SQLite
- More convenient than PostgreSQL, Spark
- Less resource intensive than Pandas, etc.

Positioning: Efficient Analysis of Data Sets of Several Hundred Gigabytes in Size

### 1.1.2. Some Example

#### 1.1.2.1. Directly using the command line

```bash
> duckdb -s "SELECT COUNT(*) FROM 'data.csv"
```

![attachments/Pasted image 20250612200854.png](attachments/Pasted%20image%2020250612200854.png)

```bash
> duckdb -csv \
-s "SELECT..." \
"new.csv"

duckdb -s "FROM 'data.csv' LIMIT 5"
```

```bash
> .mode line
> SUMMARIZE FROM 'data.csv';
columns_name = ...
columns_type = ...
.....
null percentage=...
```

![](attachments/Pasted%20image%2020250612201011.png)

```bash

> CREATE TABLE table_name AS SELECT * from 'data.csv';
> DESCRIVE table_name
```

#### 1.1.2.2. WebUI

```bash
duckdb -ui
```

![](attachments/Pasted%20image%2020250612200430.png)

#### 1.1.2.3. in Python:

```bash
pip install duckdb --upgrade
```

- SQL query

![attachments/Screenshot 2025-06-12 at 19.45.17.png](attachments/Screenshot%202025-06-12%20at%2019.45.17.png)

- Pandas integration

![attachments/Pasted image 20250612194646.png](attachments/Pasted%20image%2020250612194646.png)

#### 1.1.2.4. with other relational dababase

through plugin （e.g. `postgres_scanner`) then u can connect PostgreSQL and use its data

### 1.1.3. performance comparison

A 10GB parquet file, read and queried using DuckDB, proved to require only `400MB of memory` and `51s of runtime`. On the contrary, Pandas can't even complete the reading.

## 1.2. Vector Database

with the development of LLM

<https://www.dailydoseofds.com/a-beginner-friendly-and-comprehensive-deep-dive-on-vector-databases/>

### 1.2.1. Introduction

vector(embedings) can transmitting semantic information
![attachments/Pasted image 20250612203752.png](attachments/Pasted%20image%2020250612203752.png)

> Once stored in a vector database, we can retrieve original objects that are similar to the query we wish to run on our unstructured data.

e.g. in vector database, we have $King + Man - Woman \approx Queen$

![attachments/Pasted image 20250612204217.png](attachments/Pasted%20image%2020250612204217.png)

> In other words, encoding **unstructured data** allows us to run many sophisticated operations like similarity search, clustering, and classification over it, which otherwise is difficult with traditional databases.

However, it is hard to do it, as u need a full table scan to get it, so you need a model to do the retrieval

### 1.2.2. How to generate embeddings?

Omitted, see blog for details

### 1.2.3. Query a vector database

we need an index, and do **approximate nearest neighbor (ANN)**

#### 1.2.3.1. Flat Index

> Flat index is another name for the **brute-force search** we saw earlier, which is also done by KNN. Thus, all vectors are stored in a single index structure **without any hierarchical organization**.

![attachments/Pasted image 20250612204641.png](attachments/Pasted%20image%2020250612204641.png)

#### 1.2.3.2. Inverted File Index(IVF/IVFFlat)

Thoughts:

- Partitioning
- Pick a center point (KNN like)
- When a new query comes in and only looks at which center it is closer to, and then retrieves it in the corresponding region

![](attachments/Pasted%20image%2020250612204824.png)
![attachments/Pasted image 20250612204931.png](attachments/Pasted%20image%2020250612204931.png)

#### 1.2.3.3. Product Quantization(PQ)

> Compressing the data while preserving the original information.

Thoughts

- Create data segments
  each vector has 256-d, and 32bits each, then use 8192bits
  split it into 8, each will be 32-d
  ![](attachments/Pasted%20image%2020250612205508.png)
- run KMeans
  by k-means, we have 8 centroids
  ![](attachments/Pasted%20image%2020250612205518.png)
- encode vectors
  for each segment of a vector in the entire database, we find the nearest centroid from the respective segment
  ![](attachments/Pasted%20image%2020250612205526.png)![](attachments/Pasted%20image%2020250612205533.png)

#### 1.2.3.4. Hierarchical Navigable Small World (HNSW)

> construct a graph structure, where each node represents a data vector, and edges connect nodes based on their similarity.
> HNSW organizes the graph in such a way that facilitates fast search operations by efficiently navigating through the graph to find approximate nearest neighbors.

![](attachments/Pasted%20image%2020250612205612.png)
